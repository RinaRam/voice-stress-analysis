{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Med",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCAv3yDXuJx2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7335dbd-c509-4d55-cf0c-c8d33a29d2d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Efa6IBN-IC"
      },
      "source": [
        "import librosa\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "from sklearn.dummy import DummyClassifier\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import os\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization, Dense\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJKBf-K3iXs3",
        "outputId": "27d30fcf-0f3e-4bf2-b974-5af9a38d3b4a"
      },
      "source": [
        "pict = \"/content/drive/MyDrive/Artfct/\"\n",
        "art_folders = os.listdir(pict)\n",
        "art_folders.sort() \n",
        "art_folders"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['000', '001', '010', '011', '100', '101', '110']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "kMQafRSJjGJZ",
        "outputId": "3c2d0855-cc5d-41fc-dbc0-51e132c13e58"
      },
      "source": [
        "ball_label = []\n",
        "cod_label = []\n",
        "light_label = []\n",
        "image_id = []\n",
        "for i in art_folders:\n",
        "    filename = os.listdir(pict + i)\n",
        "    for f in filename:\n",
        "        ball_label.append(int(i[0]))\n",
        "        cod_label.append(int(i[1]))\n",
        "        light_label.append(int(i[2]))\n",
        "        image_id.append(pict + i + '/' + f)\n",
        "art_df = pd.DataFrame(light_label)\n",
        "art_df = pd.concat([pd.DataFrame(cod_label),art_df,],axis=1)\n",
        "art_df = pd.concat([pd.DataFrame(ball_label),art_df,],axis=1)\n",
        "art_df = pd.concat([pd.DataFrame(image_id),art_df,],axis=1)\n",
        "art_df.columns = ['image_id','ball_label','cod_label','light_label']\n",
        "art_df"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>ball_label</th>\n",
              "      <th>cod_label</th>\n",
              "      <th>light_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/000/C00002934974...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/000/C00002934635...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/000/C00002933560...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/000/C00002934702...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/000/C00002935700...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/110/C00002987683...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/110/C00002987683...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/110/C00002987683...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/110/C00002987648...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/110/C00002987041...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1271 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               image_id  ...  light_label\n",
              "0     /content/drive/MyDrive/Artfct/000/C00002934974...  ...            0\n",
              "1     /content/drive/MyDrive/Artfct/000/C00002934635...  ...            0\n",
              "2     /content/drive/MyDrive/Artfct/000/C00002933560...  ...            0\n",
              "3     /content/drive/MyDrive/Artfct/000/C00002934702...  ...            0\n",
              "4     /content/drive/MyDrive/Artfct/000/C00002935700...  ...            0\n",
              "...                                                 ...  ...          ...\n",
              "1266  /content/drive/MyDrive/Artfct/110/C00002987683...  ...            0\n",
              "1267  /content/drive/MyDrive/Artfct/110/C00002987683...  ...            0\n",
              "1268  /content/drive/MyDrive/Artfct/110/C00002987683...  ...            0\n",
              "1269  /content/drive/MyDrive/Artfct/110/C00002987648...  ...            0\n",
              "1270  /content/drive/MyDrive/Artfct/110/C00002987041...  ...            0\n",
              "\n",
              "[1271 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "6U_nV9EWjmN8",
        "outputId": "f4f863ea-18b4-4a65-a417-d277ab57742e"
      },
      "source": [
        "art_df = art_df.sample(frac=1).reset_index(drop=True)\n",
        "art_df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>ball_label</th>\n",
              "      <th>cod_label</th>\n",
              "      <th>light_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/010/C00002961640...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/001/C00002957536...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/010/C00002957693...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/101/C00002960756...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/001/C00002956998...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1266</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/010/C00002954951...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/010/C00002954532...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1268</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/110/C00002944809...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1269</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/010/C00002956595...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1270</th>\n",
              "      <td>/content/drive/MyDrive/Artfct/010/C00002956569...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1271 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               image_id  ...  light_label\n",
              "0     /content/drive/MyDrive/Artfct/010/C00002961640...  ...            0\n",
              "1     /content/drive/MyDrive/Artfct/001/C00002957536...  ...            1\n",
              "2     /content/drive/MyDrive/Artfct/010/C00002957693...  ...            0\n",
              "3     /content/drive/MyDrive/Artfct/101/C00002960756...  ...            1\n",
              "4     /content/drive/MyDrive/Artfct/001/C00002956998...  ...            1\n",
              "...                                                 ...  ...          ...\n",
              "1266  /content/drive/MyDrive/Artfct/010/C00002954951...  ...            0\n",
              "1267  /content/drive/MyDrive/Artfct/010/C00002954532...  ...            0\n",
              "1268  /content/drive/MyDrive/Artfct/110/C00002944809...  ...            0\n",
              "1269  /content/drive/MyDrive/Artfct/010/C00002956595...  ...            0\n",
              "1270  /content/drive/MyDrive/Artfct/010/C00002956569...  ...            0\n",
              "\n",
              "[1271 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVhlxI9b4-rY"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.resnet50 import preprocess_input\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                             rotation_range=30,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode=\"nearest\")\n",
        "\n",
        "train_df = art_df[:int(0.8*len(art_df))]\n",
        "valid_df = art_df[int(0.8*len(art_df)):]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsJApYjn4-t6",
        "outputId": "2cd4b0f7-f2fc-4463-c239-982d612fc00f"
      },
      "source": [
        "y_columns = [\"ball_label\", \"cod_label\",\"light_label\"]\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(dataframe=train_df, \n",
        "                                              x_col=\"image_id\", y_col=y_columns,\n",
        "                                              class_mode=\"raw\", \n",
        "                                              target_size=(500,500), batch_size=16,\n",
        "                                              shuffle=True)\n",
        "valid_generator = datagen.flow_from_dataframe(dataframe=valid_df, \n",
        "                                              x_col=\"image_id\", y_col=y_columns,\n",
        "                                              class_mode=\"raw\", \n",
        "                                              target_size=(500,500), batch_size=16)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1016 validated image filenames.\n",
            "Found 255 validated image filenames.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrRNsBui4-w4",
        "outputId": "ba9a2ac2-7e9e-4cea-b5f4-ee7575c3deb8"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2), input_shape=(500, 500, 3)))\n",
        "model.add(layers.Conv2D(64, kernel_size=(8), activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(128, kernel_size=(8),activation='relu',kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
        "model.add(layers.AveragePooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(6)))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Conv2D(128, kernel_size=(8),activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(6)))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Conv2D(256, kernel_size=(2),activation='relu'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.MaxPooling2D(pool_size=(1)))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(3, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001),metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "average_pooling2d_9 (Average (None, 250, 250, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 243, 243, 64)      12352     \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 243, 243, 64)      256       \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 236, 236, 128)     524416    \n",
            "_________________________________________________________________\n",
            "average_pooling2d_10 (Averag (None, 118, 118, 128)     0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 118, 118, 128)     512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 19, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 19, 19, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 12, 12, 128)       1048704   \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 12, 12, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 256)         131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 771       \n",
            "=================================================================\n",
            "Total params: 1,785,667\n",
            "Trainable params: 1,784,515\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnvSG-xT4-zq",
        "outputId": "1881139d-d91b-4ae6-c436-a16e4c025270"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit(train_generator,\n",
        "          batch_size=16,\n",
        "          epochs=64,\n",
        "          validation_data=valid_generator,\n",
        "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "          validation_steps=STEP_SIZE_VALID,\n",
        "          callbacks=[checkpoint])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "63/63 [==============================] - 128s 2s/step - loss: 1.4289 - accuracy: 0.6188 - val_loss: 2.3050 - val_accuracy: 0.7042\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.70417, saving model to best_initial_model.hdf5\n",
            "Epoch 2/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.7848 - accuracy: 0.8069 - val_loss: 1.0391 - val_accuracy: 0.7083\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.70417 to 0.70833, saving model to best_initial_model.hdf5\n",
            "Epoch 3/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.4481 - accuracy: 0.8309 - val_loss: 0.4587 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.70833 to 0.80000, saving model to best_initial_model.hdf5\n",
            "Epoch 4/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.3767 - accuracy: 0.8149 - val_loss: 0.3635 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.80000\n",
            "Epoch 5/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.3233 - accuracy: 0.8150 - val_loss: 0.2868 - val_accuracy: 0.7875\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.80000\n",
            "Epoch 6/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.3182 - accuracy: 0.8308 - val_loss: 0.2728 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.80000\n",
            "Epoch 7/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2876 - accuracy: 0.8383 - val_loss: 0.3242 - val_accuracy: 0.7875\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.80000\n",
            "Epoch 8/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.3457 - accuracy: 0.8280 - val_loss: 0.2916 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.80000 to 0.80833, saving model to best_initial_model.hdf5\n",
            "Epoch 9/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2975 - accuracy: 0.8120 - val_loss: 0.2341 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.80833\n",
            "Epoch 10/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2635 - accuracy: 0.8241 - val_loss: 0.3027 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.80833\n",
            "Epoch 11/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2673 - accuracy: 0.8342 - val_loss: 0.3987 - val_accuracy: 0.6708\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.80833\n",
            "Epoch 12/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2670 - accuracy: 0.8297 - val_loss: 0.2493 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.80833\n",
            "Epoch 13/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2475 - accuracy: 0.8343 - val_loss: 0.2574 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.80833\n",
            "Epoch 14/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2453 - accuracy: 0.8365 - val_loss: 0.4700 - val_accuracy: 0.5917\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.80833\n",
            "Epoch 15/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2358 - accuracy: 0.8448 - val_loss: 0.2829 - val_accuracy: 0.8167\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.80833 to 0.81667, saving model to best_initial_model.hdf5\n",
            "Epoch 16/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2847 - accuracy: 0.8325 - val_loss: 0.2730 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.81667\n",
            "Epoch 17/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2461 - accuracy: 0.8480 - val_loss: 0.2530 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.81667\n",
            "Epoch 18/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2753 - accuracy: 0.8361 - val_loss: 0.2478 - val_accuracy: 0.8250\n",
            "\n",
            "Epoch 00018: val_accuracy improved from 0.81667 to 0.82500, saving model to best_initial_model.hdf5\n",
            "Epoch 19/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2606 - accuracy: 0.8407 - val_loss: 0.2271 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.82500\n",
            "Epoch 20/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2620 - accuracy: 0.8321 - val_loss: 0.4111 - val_accuracy: 0.6750\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.82500\n",
            "Epoch 21/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2894 - accuracy: 0.8393 - val_loss: 0.2890 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.82500\n",
            "Epoch 22/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2920 - accuracy: 0.8120 - val_loss: 0.2715 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.82500\n",
            "Epoch 23/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2730 - accuracy: 0.8344 - val_loss: 0.2939 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.82500\n",
            "Epoch 24/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.3010 - accuracy: 0.8068 - val_loss: 0.2268 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.82500\n",
            "Epoch 25/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2286 - accuracy: 0.8462 - val_loss: 0.5703 - val_accuracy: 0.5875\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.82500\n",
            "Epoch 26/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2273 - accuracy: 0.8558 - val_loss: 0.3208 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.82500\n",
            "Epoch 27/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2734 - accuracy: 0.8344 - val_loss: 0.2693 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.82500\n",
            "Epoch 28/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2198 - accuracy: 0.8456 - val_loss: 0.3943 - val_accuracy: 0.7375\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.82500\n",
            "Epoch 29/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2739 - accuracy: 0.8281 - val_loss: 0.4663 - val_accuracy: 0.6458\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.82500\n",
            "Epoch 30/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2242 - accuracy: 0.8611 - val_loss: 0.2710 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.82500\n",
            "Epoch 31/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2715 - accuracy: 0.8330 - val_loss: 0.2699 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.82500\n",
            "Epoch 32/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2097 - accuracy: 0.8646 - val_loss: 0.4815 - val_accuracy: 0.7042\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.82500\n",
            "Epoch 33/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2596 - accuracy: 0.8322 - val_loss: 0.2505 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.82500\n",
            "Epoch 34/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2662 - accuracy: 0.8255 - val_loss: 0.2914 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.82500\n",
            "Epoch 35/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2621 - accuracy: 0.8251 - val_loss: 0.2570 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.82500\n",
            "Epoch 36/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2111 - accuracy: 0.8504 - val_loss: 0.2793 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.82500\n",
            "Epoch 37/64\n",
            "63/63 [==============================] - 124s 2s/step - loss: 0.2231 - accuracy: 0.8513 - val_loss: 0.2879 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.82500\n",
            "Epoch 38/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2825 - accuracy: 0.8542 - val_loss: 0.2455 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.82500\n",
            "Epoch 39/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2289 - accuracy: 0.8383 - val_loss: 0.2449 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.82500\n",
            "Epoch 40/64\n",
            "63/63 [==============================] - 124s 2s/step - loss: 0.3018 - accuracy: 0.8089 - val_loss: 0.2439 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.82500\n",
            "Epoch 41/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2406 - accuracy: 0.8658 - val_loss: 0.2816 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.82500\n",
            "Epoch 42/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2255 - accuracy: 0.8566 - val_loss: 0.2390 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.82500\n",
            "Epoch 43/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2150 - accuracy: 0.8489 - val_loss: 0.2487 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.82500\n",
            "Epoch 44/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.1963 - accuracy: 0.8434 - val_loss: 0.3966 - val_accuracy: 0.7667\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.82500\n",
            "Epoch 45/64\n",
            "63/63 [==============================] - 127s 2s/step - loss: 0.2428 - accuracy: 0.8413 - val_loss: 0.2868 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.82500\n",
            "Epoch 46/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2506 - accuracy: 0.8433 - val_loss: 0.2457 - val_accuracy: 0.7792\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.82500\n",
            "Epoch 47/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.1988 - accuracy: 0.8624 - val_loss: 0.2584 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.82500\n",
            "Epoch 48/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2358 - accuracy: 0.8436 - val_loss: 0.2478 - val_accuracy: 0.8167\n",
            "\n",
            "Epoch 00048: val_accuracy did not improve from 0.82500\n",
            "Epoch 49/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2400 - accuracy: 0.8581 - val_loss: 0.2387 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00049: val_accuracy did not improve from 0.82500\n",
            "Epoch 50/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2595 - accuracy: 0.8199 - val_loss: 0.2666 - val_accuracy: 0.8167\n",
            "\n",
            "Epoch 00050: val_accuracy did not improve from 0.82500\n",
            "Epoch 51/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2287 - accuracy: 0.8539 - val_loss: 0.3969 - val_accuracy: 0.7583\n",
            "\n",
            "Epoch 00051: val_accuracy did not improve from 0.82500\n",
            "Epoch 52/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2748 - accuracy: 0.8396 - val_loss: 0.3198 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00052: val_accuracy did not improve from 0.82500\n",
            "Epoch 53/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2415 - accuracy: 0.8491 - val_loss: 0.3032 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00053: val_accuracy did not improve from 0.82500\n",
            "Epoch 54/64\n",
            "63/63 [==============================] - 128s 2s/step - loss: 0.2537 - accuracy: 0.8518 - val_loss: 0.2344 - val_accuracy: 0.8000\n",
            "\n",
            "Epoch 00054: val_accuracy did not improve from 0.82500\n",
            "Epoch 55/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2186 - accuracy: 0.8597 - val_loss: 0.2861 - val_accuracy: 0.7958\n",
            "\n",
            "Epoch 00055: val_accuracy did not improve from 0.82500\n",
            "Epoch 56/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2870 - accuracy: 0.8233 - val_loss: 0.3006 - val_accuracy: 0.7583\n",
            "\n",
            "Epoch 00056: val_accuracy did not improve from 0.82500\n",
            "Epoch 57/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2417 - accuracy: 0.8526 - val_loss: 0.2668 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00057: val_accuracy did not improve from 0.82500\n",
            "Epoch 58/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2584 - accuracy: 0.8475 - val_loss: 0.2630 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00058: val_accuracy did not improve from 0.82500\n",
            "Epoch 59/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2425 - accuracy: 0.8444 - val_loss: 0.2702 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00059: val_accuracy did not improve from 0.82500\n",
            "Epoch 60/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2587 - accuracy: 0.8471 - val_loss: 0.2830 - val_accuracy: 0.8042\n",
            "\n",
            "Epoch 00060: val_accuracy did not improve from 0.82500\n",
            "Epoch 61/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2259 - accuracy: 0.8641 - val_loss: 0.8244 - val_accuracy: 0.4125\n",
            "\n",
            "Epoch 00061: val_accuracy did not improve from 0.82500\n",
            "Epoch 62/64\n",
            "63/63 [==============================] - 126s 2s/step - loss: 0.2320 - accuracy: 0.8477 - val_loss: 0.2656 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00062: val_accuracy did not improve from 0.82500\n",
            "Epoch 63/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2265 - accuracy: 0.8498 - val_loss: 0.2833 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00063: val_accuracy did not improve from 0.82500\n",
            "Epoch 64/64\n",
            "63/63 [==============================] - 125s 2s/step - loss: 0.2112 - accuracy: 0.8649 - val_loss: 0.2442 - val_accuracy: 0.8083\n",
            "\n",
            "Epoch 00064: val_accuracy did not improve from 0.82500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdd9c26dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76TH_Vg5mfdF"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import resnet50\n",
        "\n",
        "base_model = ResNet50(include_top=False,\n",
        "                      weights='imagenet',\n",
        "                      pooling='avg')\n",
        "'''\n",
        "x = base_model.output\n",
        "x = Dense(1000, activation='relu')(x)\n",
        "x = Dropout(rate=0.2)(x)\n",
        "out = Dense(3, activation='sigmoid')(x)\n",
        "model = keras.Model(inputs=base_model.input, outputs=out)\n",
        "\n",
        "base_model = ResNet50(include_top=False, \n",
        "                      weights='imagenet', \n",
        "                      input_shape=(2000, 2000, 3))\n",
        "'''\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.AveragePooling2D(pool_size=(4, 4), input_shape=(2000, 2000, 3)))\n",
        "model.add(base_model)\n",
        "#model.add(Flatten())\n",
        "#model.add(Dense(1000, activation=\"relu\"))\n",
        "#model.add(Dropout(0.2))\n",
        "model.add(Dense(3, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.001),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9OrRspYiRV3",
        "outputId": "cd35b943-c623-4c77-a37c-ac9f40f93ce2"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"best_initial_model.hdf5\", monitor='val_accuracy', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
        "model.fit(train_generator,\n",
        "          batch_size=16,\n",
        "          epochs=64,\n",
        "          validation_data=valid_generator,\n",
        "          steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "          validation_steps=STEP_SIZE_VALID,\n",
        "          callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/64\n",
            "25/25 [==============================] - 759s 30s/step - loss: 0.5722 - accuracy: 0.7244 - val_loss: 842514.8125 - val_accuracy: 0.4271\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.42708, saving model to best_initial_model.hdf5\n",
            "Epoch 2/64\n",
            "25/25 [==============================] - 510s 21s/step - loss: 0.4162 - accuracy: 0.7479 - val_loss: 72867.8750 - val_accuracy: 0.1771\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.42708\n",
            "Epoch 3/64\n",
            "25/25 [==============================] - 502s 20s/step - loss: 0.3461 - accuracy: 0.7717 - val_loss: 14450.1299 - val_accuracy: 0.4271\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.42708\n",
            "Epoch 4/64\n",
            "25/25 [==============================] - 505s 20s/step - loss: 0.3472 - accuracy: 0.8000 - val_loss: 378.5050 - val_accuracy: 0.4062\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.42708\n",
            "Epoch 5/64\n",
            "25/25 [==============================] - 513s 21s/step - loss: 0.3499 - accuracy: 0.7768 - val_loss: 30.1032 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.42708 to 0.66667, saving model to best_initial_model.hdf5\n",
            "Epoch 6/64\n",
            "25/25 [==============================] - 521s 21s/step - loss: 0.3208 - accuracy: 0.7897 - val_loss: 9.0965 - val_accuracy: 0.7917\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.66667 to 0.79167, saving model to best_initial_model.hdf5\n",
            "Epoch 7/64\n",
            "25/25 [==============================] - 512s 21s/step - loss: 0.4044 - accuracy: 0.7705 - val_loss: 3.6730 - val_accuracy: 0.4375\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.79167\n",
            "Epoch 8/64\n",
            "25/25 [==============================] - 510s 21s/step - loss: 0.2977 - accuracy: 0.8415 - val_loss: 2.2577 - val_accuracy: 0.8125\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.79167 to 0.81250, saving model to best_initial_model.hdf5\n",
            "Epoch 9/64\n",
            "25/25 [==============================] - 504s 20s/step - loss: 0.3085 - accuracy: 0.7956 - val_loss: 9.2936 - val_accuracy: 0.4062\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.81250\n",
            "Epoch 10/64\n",
            "25/25 [==============================] - 507s 20s/step - loss: 0.2981 - accuracy: 0.8182 - val_loss: 10.3393 - val_accuracy: 0.3958\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.81250\n",
            "Epoch 11/64\n",
            "25/25 [==============================] - 512s 21s/step - loss: 0.2850 - accuracy: 0.8304 - val_loss: 21.8536 - val_accuracy: 0.3854\n",
            "\n",
            "Epoch 00011: val_accuracy did not improve from 0.81250\n",
            "Epoch 12/64\n",
            "25/25 [==============================] - 499s 20s/step - loss: 0.3081 - accuracy: 0.8186 - val_loss: 3.8372 - val_accuracy: 0.3854\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.81250\n",
            "Epoch 13/64\n",
            "25/25 [==============================] - 508s 20s/step - loss: 0.2836 - accuracy: 0.8435 - val_loss: 0.4910 - val_accuracy: 0.7500\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.81250\n",
            "Epoch 14/64\n",
            "25/25 [==============================] - 516s 21s/step - loss: 0.2888 - accuracy: 0.8347 - val_loss: 0.3648 - val_accuracy: 0.8021\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.81250\n",
            "Epoch 15/64\n",
            "25/25 [==============================] - 519s 21s/step - loss: 0.2724 - accuracy: 0.8431 - val_loss: 0.3833 - val_accuracy: 0.6146\n",
            "\n",
            "Epoch 00015: val_accuracy did not improve from 0.81250\n",
            "Epoch 16/64\n",
            "25/25 [==============================] - 506s 20s/step - loss: 0.2781 - accuracy: 0.8307 - val_loss: 0.3733 - val_accuracy: 0.7396\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.81250\n",
            "Epoch 17/64\n",
            "25/25 [==============================] - 508s 20s/step - loss: 0.2466 - accuracy: 0.8556 - val_loss: 0.3729 - val_accuracy: 0.6667\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.81250\n",
            "Epoch 18/64\n",
            "25/25 [==============================] - 504s 20s/step - loss: 0.2643 - accuracy: 0.8575 - val_loss: 0.4181 - val_accuracy: 0.6354\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.81250\n",
            "Epoch 19/64\n",
            "25/25 [==============================] - 498s 20s/step - loss: 0.2541 - accuracy: 0.8414 - val_loss: 0.4383 - val_accuracy: 0.7396\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.81250\n",
            "Epoch 20/64\n",
            "12/25 [=============>................] - ETA: 3:18 - loss: 0.3169 - accuracy: 0.8224"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Or2KSPfyPuZd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luFiF92owdTS"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from skimage.io import imread\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Conv2D, MaxPooling2D, Flatten, Dense, \n",
        "                          Dropout, Activation, BatchNormalization)\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "from skimage.transform import resize, rotate\n",
        "\n",
        "AXIS_SIZE = 224\n",
        "NUMBER_CLASSES = 3\n",
        "EPOCHS_NUMBER = 20\n",
        "BATCHS_NUMBER = 256\n",
        "\n",
        "\n",
        "def resize_img(img):\n",
        "    new_img = resize(img, (AXIS_SIZE, AXIS_SIZE, 3))\n",
        "    return new_img\n",
        "\n",
        "\n",
        "# Зеркалирование по горизонтали\n",
        "def flip_img(img):\n",
        "    new_img = np.fliplr(img)\n",
        "    return new_img\n",
        "\n",
        "\n",
        "# Поворот на небольшой угол\n",
        "def random_rotate_img(img):\n",
        "    alpha_deg = np.random.randint(-17, 17)\n",
        "    new_img = rotate(img, alpha_deg, mode='edge')\n",
        "    return new_img\n",
        "\n",
        "\n",
        "# Кадрирование\n",
        "def framing_img(img, j):\n",
        "    if (j == 0):\n",
        "        left_edge = int(0.05 * AXIS_SIZE)\n",
        "        right_edge = int(0.95 * AXIS_SIZE)\n",
        "    if (j == 1):\n",
        "        left_edge = int(0.075 * AXIS_SIZE)\n",
        "        right_edge = int(0.925 * AXIS_SIZE)\n",
        "    new_img = img[left_edge : right_edge, left_edge : right_edge]\n",
        "    new_img = resize_img(new_img)\n",
        "    return new_img\n",
        "\n",
        "\n",
        "def get_model():\n",
        "    epochs =  EPOCHS_NUMBER\n",
        "    batch_sz = BATCHS_NUMBER\n",
        "    resnet_my = ResNet50(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(AXIS_SIZE, AXIS_SIZE, 3))\n",
        "    \n",
        "    X, y = load_data_to_train(resnet_my)\n",
        "    \n",
        "    sz = np.prod(resnet_my.layers[-1].output.shape[1:])\n",
        "    model_class = Sequential()\n",
        "    model_class.add(Dense(256, input_dim=int(sz)))\n",
        "    model_class.add(Dropout(0.4))\n",
        "    model_class.add(Activation('relu'))\n",
        "    model_class.add(Dense(50))\n",
        "    model_class.add(Activation('softmax'))\n",
        "    \n",
        "    #callbacks = [ModelCheckpoint('birds_model.hdf5', monitor='val_loss', save_best_only=True)]\n",
        "    \n",
        "    model_class.compile(loss='categorical_crossentropy', \n",
        "                        optimizer=adam(lr=1e-5), \n",
        "                        metrics=['accuracy'])\n",
        "    '''\n",
        "    history = model_class.fit(\n",
        "        X,\n",
        "        y,\n",
        "        batch_size=batch_sz,\n",
        "        epochs=epochs,\n",
        "        validation_split=0.1,\n",
        "        verbose=2,\n",
        "        callbacks=callbacks)\n",
        "    '''\n",
        "    \n",
        "    model_class.fit(X, y, epochs=epochs, batch_size=batch_sz, verbose=1)\n",
        "    \n",
        "    model_final = Sequential()\n",
        "    model_final.add(resnet_my)\n",
        "    model_final.add(Flatten())\n",
        "    model_final.add(model_class)\n",
        "\n",
        "    #model_final.save('med_model.hdf5')\n",
        "    \n",
        "    return \n",
        "\n",
        "\n",
        "def load_data_to_train(resnet_my):\n",
        "    old_total = len(art_df)\n",
        "    total = old_total * 4 * 4 / 5\n",
        "    sz = np.prod(resnet_my.layers[-1].output.shape[1:])\n",
        "    sz = int(sz)\n",
        "    X = (np.zeros((total * sz))).reshape(total, sz)\n",
        "    y = (np.zeros((total * NUMBER_CLASSES))).reshape(total, NUMBER_CLASSES)\n",
        "    for i, (filename, class_label) in enumerate(art_df):\n",
        "        img = imread(filename)\n",
        "        img = resize_img(img)\n",
        "        new_img = image.array_to_img(img)\n",
        "        X[i] = (resnet_my.predict(np.expand_dims(image.img_to_array(new_img), axis=0))).ravel()\n",
        "        y[i][int(class_label)] = 1\n",
        "        iid = old_total * 1 + i\n",
        "        new_img = flip_img(img)\n",
        "        new_img = image.img_to_array(image.array_to_img(new_img)) # to keras format\n",
        "        X[iid] = (resnet_my.predict(np.expand_dims(new_img, axis=0))).ravel()\n",
        "        y[iid][int(class_label)] = 1\n",
        "        iid = old_total * 2 + i * 1 + j\n",
        "        new_img = random_rotate_img(img)\n",
        "        new_img = image.img_to_array(image.array_to_img(new_img)) # to keras format\n",
        "        X[iid] = (resnet_my.predict(np.expand_dims(new_img, axis=0))).ravel()\n",
        "        y[iid][int(class_label)] = 1\n",
        "        iid = old_total * 3 + i * 1 + j\n",
        "        new_img = framing_img(img, j)\n",
        "        new_img = image.img_to_array(image.array_to_img(new_img)) # to keras format\n",
        "        X[iid] = (resnet_my.predict(np.expand_dims(new_img, axis=0))).ravel()\n",
        "        y[iid][int(class_label)] = 1\n",
        "        if i + 1 == total:\n",
        "            break\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def load_data_to_test():\n",
        "    old_total = len(art_df)\n",
        "    i = old_total * 4 * 4 / 5\n",
        "    X = np.zeros((total, AXIS_SIZE, AXIS_SIZE, 3))\n",
        "    while (i < old_total):\n",
        "        filename = art_df[image_id][i]\n",
        "        img = imread(filename)\n",
        "        img = resize_img(img)\n",
        "        X[i] = image.img_to_array(image.array_to_img(img)) # to keras format\n",
        "    return X, all_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "QvqcGbw_0gH7",
        "outputId": "dea48400-c00a-42bc-dc76-2a340187a995"
      },
      "source": [
        "get_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-5910f2cc8267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-35-320cf9202b0c>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         input_shape=(AXIS_SIZE, AXIS_SIZE, 3))\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_to_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-35-320cf9202b0c>\u001b[0m in \u001b[0;36mload_data_to_train\u001b[0;34m(resnet_my)\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mNUMBER_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUMBER_CLASSES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_label\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mart_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-KujIEX1xCz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}